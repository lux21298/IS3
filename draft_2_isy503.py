# -*- coding: utf-8 -*-
"""Draft 2 ISY503

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_E1lJpNhQbfMIs-xDdx9HvQh274R6RIP
"""

# Commented out IPython magic to ensure Python compatibility.
# Essential data manipulation and visualization libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Text processing libraries
import nltk
import re
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

# ML/DL libraries
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# For file extraction and downloading
import os
import tarfile
import gzip
import shutil
import wget

# Download required NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Configure plot settings
plt.style.use('ggplot')
# %matplotlib inline

# Mount Google Drive for persistent storage
# Uncomment and run if you want to save model weights or processed data
from google.colab import drive
drive.mount('/content/drive')

# Create a data directory
data_dir = 'data'
os.makedirs(data_dir, exist_ok=True)

# Download the Multi-Domain Sentiment Dataset
print("Downloading Multi-Domain Sentiment Dataset...")
sentiment_url = "https://www.cs.jhu.edu/~mdredze/datasets/sentiment/domain_sentiment_data.tar.gz"
sentiment_file_path = os.path.join(data_dir, "domain_sentiment_data.tar.gz")

if not os.path.exists(sentiment_file_path):
    wget.download(sentiment_url, sentiment_file_path)
    print(f"\nDownloaded to {sentiment_file_path}")
else:
    print(f"File already exists at {sentiment_file_path}")

# Download the Books unlabeled data
print("\nDownloading Books unlabeled data...")
books_url = "https://www.cs.jhu.edu/~mdredze/datasets/sentiment/book.unlabeled.gz"
books_file_path = os.path.join(data_dir, "book.unlabeled.gz")

if not os.path.exists(books_file_path):
    wget.download(books_url, books_file_path)
    print(f"\nDownloaded to {books_file_path}")
else:
    print(f"File already exists at {books_file_path}")

# Extract the downloaded tar.gz file
print("\nExtracting the Multi-Domain Sentiment Dataset...")
extracted_dir = os.path.join(data_dir, "extracted")
os.makedirs(extracted_dir, exist_ok=True)

with tarfile.open(sentiment_file_path, 'r:gz') as tar:
    tar.extractall(path=extracted_dir)
    print(f"Extracted to {extracted_dir}")

# Extract the books unlabeled data
print("\nExtracting the Books unlabeled data...")
books_extracted_path = os.path.join(extracted_dir, "book.unlabeled")
with gzip.open(books_file_path, 'rb') as f_in:
    with open(books_extracted_path, 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)
        print(f"Extracted to {books_extracted_path}")

# Move book.unlabeled to sorted_data_acl/books directory and rename to unlabeled.review
print("\nOrganizing unlabeled reviews data...")
sorted_data_acl_dir = os.path.join(extracted_dir, "sorted_data_acl")
books_dir = os.path.join(sorted_data_acl_dir, "books")

# Create directories if they don't exist
os.makedirs(books_dir, exist_ok=True)

# Set destination path
unlabeled_reviews_path = os.path.join(books_dir, "unlabeled.review")

# Copy the file to the new location with the new name
shutil.copy2(books_extracted_path, unlabeled_reviews_path)
print(f"Copied unlabeled reviews to {unlabeled_reviews_path}")

# Ensure other domain directories have the structure we need
for domain in ["electronics", "dvd", "kitchen_&_housewares"]:
    domain_dir = os.path.join(sorted_data_acl_dir, domain)
    os.makedirs(domain_dir, exist_ok=True)
    print(f"Ensured directory exists: {domain_dir}")

print("\nDirectory structure created with the following organization:")
print("sorted_data_acl/")
print("  ├── books/")
print("  │   ├── positive.review")
print("  │   ├── negative.review")
print("  │   └── unlabeled.review")
print("  ├── electronics/")
print("  │   ├── positive.review")
print("  │   ├── negative.review")
print("  │   └── unlabeled.review")
print("  ├── dvd/")
print("  │   ├── positive.review")
print("  │   ├── negative.review")
print("  │   └── unlabeled.review")
print("  └── kitchen_&_housewares/")
print("      ├── positive.review")
print("      ├── negative.review")
print("      └── unlabeled.review")

# Add BeautifulSoup for XML parsing
!pip install beautifulsoup4
from bs4 import BeautifulSoup
import glob
import html
import unicodedata

def parse_xml_review(xml_content):
    """
    Parse an XML-formatted review and extract relevant fields

    Args:
        xml_content: String containing XML review content

    Returns:
        dict: Dictionary containing extracted review fields
    """
    try:
        # Ensure we have valid content to parse
        if not xml_content or not isinstance(xml_content, str):
            print("Warning: Invalid XML content provided")
            return None

        # Try multiple parsers for robustness
        parsers = ['xml', 'html.parser', 'lxml', 'html5lib']
        soup = None

        for parser in parsers:
            try:
                soup = BeautifulSoup(xml_content, parser)
                # Check if we got a valid review tag
                if soup and soup.find('review'):
                    break
            except Exception as e:
                print(f"Parser {parser} failed: {e}")
                continue

        # If all parsers failed, use the default html.parser as fallback
        if soup is None or soup.find('review') is None:
            soup = BeautifulSoup(xml_content, 'html.parser')

        # Extract fields
        review_data = {
            'unique_id': get_tag_text(soup, 'unique_id'),
            'asin': get_tag_text(soup, 'asin'),
            'product_name': get_tag_text(soup, 'product_name'),
            'product_type': get_tag_text(soup, 'product_type'),
            'helpful': get_tag_text(soup, 'helpful'),
            'rating': get_tag_text(soup, 'rating'),
            'title': get_tag_text(soup, 'title'),
            'date': get_tag_text(soup, 'date'),
            'reviewer': get_tag_text(soup, 'reviewer'),
            'reviewer_location': get_tag_text(soup, 'reviewer_location'),
            'review_text': get_tag_text(soup, 'review_text')
        }

        # Convert rating to float if possible
        try:
            review_data['rating'] = float(review_data['rating'])
        except (ValueError, TypeError):
            # If rating can't be converted to float, set it to None
            review_data['rating'] = None

        return review_data
    except Exception as e:
        print(f"Error parsing XML review: {e}")
        return None

def get_tag_text(soup, tag_name):
    """
    Helper function to extract text from a tag and handle missing tags

    Args:
        soup: BeautifulSoup object
        tag_name: Name of the tag to extract

    Returns:
        str: Text content of the tag or None if tag not found
    """
    try:
        if soup is None:
            return None

        tag = soup.find(tag_name)
        if tag:
            # Fix encoding issues
            text = tag.get_text(strip=True)
            text = fix_encoding(text)
            return text
        return None
    except Exception as e:
        print(f"Error extracting {tag_name}: {e}")
        return None

def fix_encoding(text):
    """
    Fix common encoding issues in text

    Args:
        text: Text with potential encoding issues

    Returns:
        str: Text with fixed encoding
    """
    try:
        if text is None:
            return None

        # Common encoding issues mapping
        encoding_fixes = {
            '�': 'á',
            '�': 'é',
            '�': 'í',
            '�': 'ó',
            '�': 'ú',
            '�': 'ñ',
            '�': 'ü',
            '�': '€',
            '�': '"',
            '�': '"'
        }

        # Replace common problematic characters
        for char, replacement in encoding_fixes.items():
            text = text.replace(char, replacement)

        # Try different normalizations for better compatibility
        try:
            text = unicodedata.normalize('NFC', text)
        except Exception:
            try:
                text = unicodedata.normalize('NFKC', text)
            except Exception:
                pass  # If all normalizations fail, continue with the original text

        # Decode HTML entities
        text = html.unescape(text)

        # Remove any remaining control characters
        text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C')

        return text
    except Exception as e:
        print(f"Error fixing encoding: {e}")
        # Return the original text if any error occurs
        return text if text is not None else ""

def load_xml_reviews_from_file(file_path):
    """
    Load and parse reviews from an XML file

    Args:
        file_path: Path to the XML file

    Returns:
        list: List of parsed review dictionaries
    """
    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as file:
            content = file.read()

            # Check if file contains multiple reviews
            if content.count('<review>') > 1:
                # Split into individual reviews
                reviews = []
                soup = BeautifulSoup(content, 'html.parser')
                for review_tag in soup.find_all('review'):
                    review_data = parse_xml_review(str(review_tag))
                    if review_data:
                        reviews.append(review_data)
                return reviews
            else:
                # Single review
                review_data = parse_xml_review(content)
                return [review_data] if review_data else []
    except Exception as e:
        print(f"Error loading XML file {file_path}: {e}")
        return []

def load_xml_reviews_from_directory(directory_path, file_pattern="*.md"):
    """
    Load and parse reviews from XML files in a directory

    Args:
        directory_path: Path to the directory containing XML files
        file_pattern: Pattern to match XML files

    Returns:
        list: List of parsed review dictionaries
    """
    all_reviews = []

    # Get list of files matching pattern
    file_paths = glob.glob(os.path.join(directory_path, file_pattern))

    for file_path in file_paths:
        reviews = load_xml_reviews_from_file(file_path)
        all_reviews.extend(reviews)

    return all_reviews

def convert_reviews_to_sentiment_dataset(reviews, sentiment_label):
    """
    Convert parsed reviews to sentiment dataset format (text and label)

    Args:
        reviews: List of review dictionaries
        sentiment_label: Label to assign to reviews (1 for positive, 0 for negative)

    Returns:
        tuple: (texts, labels, additional_info)
            - texts: List of review texts
            - labels: List of sentiment labels (1 for positive, 0 for negative)
            - additional_info: List of dictionaries with additional review information
    """
    texts = []
    labels = []
    additional_info = []

    for review in reviews:
        if review and 'review_text' in review and review['review_text']:
            # Add review text
            texts.append(review['review_text'])

            # Use provided sentiment label
            labels.append(sentiment_label)

            # Add additional information
            info = {
                'product_type': review.get('product_type'),
                'title': review.get('title'),
                'rating': review.get('rating')
            }
            additional_info.append(info)

    return texts, labels, additional_info

# Test the XML parsing functionality with the sample file
sample_review_path = os.path.join(os.getcwd(), "sample_review.md")

if os.path.exists(sample_review_path):
    print("Processing sample XML review file...")
    sample_reviews = load_xml_reviews_from_file(sample_review_path)

    if sample_reviews:
        print(f"Successfully parsed {len(sample_reviews)} review(s)")

        # Display the first review
        print("\nSample parsed review:")
        for key, value in sample_reviews[0].items():
            print(f"{key}: {value}")

        # Convert to sentiment dataset using a positive sentiment label (5-star review)
        texts, labels, additional_info = convert_reviews_to_sentiment_dataset(sample_reviews, 1)

        print(f"\nConverted to sentiment dataset:")
        print(f"Number of texts: {len(texts)}")
        print(f"Number of labels: {len(labels)}")

        if len(texts) > 0:
            print(f"\nSample text: {texts[0]}")
            print(f"Sample label: {labels[0]} (Sentiment: {'Positive' if labels[0] == 1 else 'Negative'})")
    else:
        print("Failed to parse the sample review file.")
else:
    print("Sample review file not found. XML parsing will be available when running with actual data.")

# List the extracted directories and files
print("Exploring the extracted directory structure:")
for root, dirs, files in os.walk(extracted_dir):
    level = root.replace(extracted_dir, '').count(os.sep)
    indent = ' ' * 4 * level
    print(f"{indent}{os.path.basename(root)}/")
    sub_indent = ' ' * 4 * (level + 1)
    for file in files[:5]:  # Limit to first 5 files for brevity
        print(f"{sub_indent}{file}")
    if len(files) > 5:
        print(f"{sub_indent}... ({len(files)-5} more files)")

# Function to load XML reviews from a file and determine sentiment from filename
def load_xml_reviews_with_sentiment(file_path):
    """
    Load XML-formatted reviews from a file and determine sentiment based on filename

    Args:
        file_path: Path to the review file

    Returns:
        tuple: (reviews, sentiment_label)
            - reviews: List of parsed review dictionaries
            - sentiment_label: 1 for positive, 0 for negative
    """
    # Determine sentiment based on filename
    file_name = os.path.basename(file_path).lower()
    sentiment_label = 1 if "positive" in file_name else 0

    # Load reviews from file
    reviews = []
    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as file:
            content = file.read()

            # Parse XML reviews
            soup = BeautifulSoup(content, 'html.parser')
            review_tags = soup.find_all('review')

            if review_tags and len(review_tags) > 0:
                # Process multiple reviews
                for review_tag in review_tags:
                    review_data = parse_xml_review(str(review_tag))
                    if review_data and review_data.get('review_text'):
                        # Add sentiment label
                        review_data['sentiment'] = sentiment_label
                        reviews.append(review_data)
            else:
                # No review tags found, try to process as a text file with one review per line
                lines = content.strip().split('\n')
                for line in lines:
                    # Check if the line is not empty
                    if line.strip():
                        # Create a simple review dictionary
                        review_data = {
                            'review_text': line.strip(),
                            'sentiment': sentiment_label
                        }
                        reviews.append(review_data)

        return reviews, sentiment_label
    except Exception as e:
        print(f"Error loading reviews from {file_path}: {e}")
        return [], sentiment_label

# Define function to extract review text from files
def extract_reviews_from_file(file_path):
    """
    Extract review text from a file, handling both XML and plain text formats

    Args:
        file_path: Path to the review file

    Returns:
        list: List of review texts
    """
    review_texts = []

    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as file:
            content = file.read()

            # Check if this is XML format (contains <review> tags)
            if '<review>' in content:
                soup = BeautifulSoup(content, 'html.parser')
                # Find all review tags
                review_tags = soup.find_all('review')

                for review_tag in review_tags:
                    # Find the review_text tag
                    review_text_tag = review_tag.find('review_text')
                    if review_text_tag:
                        text = review_text_tag.get_text(strip=True)
                        text = fix_encoding(text)
                        if text.strip():
                            review_texts.append(text)
            else:
                # Process as plain text file, one review per line
                lines = content.strip().split('\n')
                for line in lines:
                    if line.strip():
                        review_texts.append(line.strip())

        return review_texts
    except Exception as e:
        print(f"Error extracting reviews from {file_path}: {e}")
        return []

# Get the correct directory structure based on the directory_structure.md
sorted_data_dir = os.path.join(extracted_dir, "sorted_data_acl")

# Check for the directory structure using listdir for domains
if os.path.exists(sorted_data_dir):
    domains = [d for d in os.listdir(sorted_data_dir) if os.path.isdir(os.path.join(sorted_data_dir, d))]
    print(f"Found domains: {domains}")
else:
    print(f"Warning: Directory '{sorted_data_dir}' not found.")
    # Try the original directory structure as fallback
    sorted_data_dir = os.path.join(extracted_dir, "sorted_data")
    if os.path.exists(sorted_data_dir):
        domains = [d for d in os.listdir(sorted_data_dir) if os.path.isdir(os.path.join(sorted_data_dir, d))]
        print(f"Using fallback directory. Found domains: {domains}")
    else:
        print("Warning: No valid data directory found.")
        domains = []

# Function to load all reviews from domains
def load_domain_reviews(domains, sorted_data_dir):
    """
    Load all reviews from specified domains, separating positive and negative reviews

    Args:
        domains: List of domain names
        sorted_data_dir: Base directory containing domain subdirectories

    Returns:
        tuple: (all_texts, all_labels, all_domains)
            - all_texts: List of preprocessed review texts
            - all_labels: List of sentiment labels (1 for positive, 0 for negative)
            - all_domains: List of domain names for each review
    """
    all_texts = []
    all_labels = []
    all_domains = []

    print("Loading reviews from all domains...")

    # Process each domain
    for domain in domains:
        domain_dir = os.path.join(sorted_data_dir, domain)

        # Process positive reviews
        pos_file_path = os.path.join(domain_dir, "positive.review")
        if os.path.exists(pos_file_path):
            pos_reviews = extract_reviews_from_file(pos_file_path)
            print(f"Loaded {len(pos_reviews)} positive reviews from {domain}")

            # Process and add each review
            for review_text in pos_reviews:
                all_texts.append(review_text)
                all_labels.append(1)  # 1 for positive
                all_domains.append(domain)

        # Process negative reviews
        neg_file_path = os.path.join(domain_dir, "negative.review")
        if os.path.exists(neg_file_path):
            neg_reviews = extract_reviews_from_file(neg_file_path)
            print(f"Loaded {len(neg_reviews)} negative reviews from {domain}")

            # Process and add each review
            for review_text in neg_reviews:
                all_texts.append(review_text)
                all_labels.append(0)  # 0 for negative
                all_domains.append(domain)

    return all_texts, all_labels, all_domains

# Try to load sample reviews from the first domain if available
if domains:
    sample_domain = domains[0]
    pos_file_path = os.path.join(sorted_data_dir, sample_domain, "positive.review")
    neg_file_path = os.path.join(sorted_data_dir, sample_domain, "negative.review")

    # Extract sample reviews
    sample_pos_reviews = extract_reviews_from_file(pos_file_path) if os.path.exists(pos_file_path) else []
    sample_neg_reviews = extract_reviews_from_file(neg_file_path) if os.path.exists(neg_file_path) else []

    print(f"Loaded {len(sample_pos_reviews)} positive reviews and {len(sample_neg_reviews)} negative reviews from {sample_domain} for samples")

    # Display samples of positive and negative reviews
    if sample_pos_reviews:
        print("\nSample positive review:")
        review_text = sample_pos_reviews[0]
        print(review_text[:500] + "..." if len(review_text) > 500 else review_text)

    if sample_neg_reviews:
        print("\nSample negative review:")
        review_text = sample_neg_reviews[0]
        print(review_text[:500] + "..." if len(review_text) > 500 else review_text)
else:
    print("No domains found to load sample reviews.")
    sample_pos_reviews = []
    sample_neg_reviews = []

# Calculate review lengths for samples from each domain
print("Analyzing review lengths from all domains...")

# Load all review texts for analysis
all_reviews = []
all_sentiments = []
domain_markers = []

# Process each domain
for domain in domains:
    domain_dir = os.path.join(sorted_data_dir, domain)

    # Process positive reviews
    pos_path = os.path.join(domain_dir, "positive.review")
    if os.path.exists(pos_path):
        pos_reviews = extract_reviews_from_file(pos_path)
        all_reviews.extend(pos_reviews)
        all_sentiments.extend(["Positive"] * len(pos_reviews))
        domain_markers.extend([domain] * len(pos_reviews))

    # Process negative reviews
    neg_path = os.path.join(domain_dir, "negative.review")
    if os.path.exists(neg_path):
        neg_reviews = extract_reviews_from_file(neg_path)
        all_reviews.extend(neg_reviews)
        all_sentiments.extend(["Negative"] * len(neg_reviews))
        domain_markers.extend([domain] * len(neg_reviews))

# Calculate review lengths
review_lengths = [len(review.split()) for review in all_reviews]

# Create DataFrame for analysis
review_analysis_df = pd.DataFrame({
    'Review': all_reviews,
    'Sentiment': all_sentiments,
    'Domain': domain_markers,
    'Length': review_lengths
})

# Calculate statistics by sentiment
stats_by_sentiment = review_analysis_df.groupby('Sentiment')['Length'].describe()
print("Review Length Statistics by Sentiment:")
print(stats_by_sentiment)

# Calculate statistics by domain
stats_by_domain = review_analysis_df.groupby('Domain')['Length'].describe()
print("\nReview Length Statistics by Domain:")
print(stats_by_domain)

# Create DataFrame for plotting
review_lengths_by_sentiment = {}
for sentiment in review_analysis_df['Sentiment'].unique():
    review_lengths_by_sentiment[sentiment] = review_analysis_df[review_analysis_df['Sentiment'] == sentiment]['Length'].values

review_lengths_plot_df = pd.DataFrame(review_lengths_by_sentiment)

# Visualize review length distributions
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
sns.histplot(data=review_analysis_df, x='Length', hue='Sentiment', bins=50, alpha=0.7)
plt.xlabel('Review Length (words)')
plt.ylabel('Count')
plt.title('Distribution of Review Lengths by Sentiment')
plt.xlim(0, 1000)  # Limit x-axis for better visualization

plt.subplot(1, 2, 2)
sns.boxplot(data=review_analysis_df, x='Sentiment', y='Length')
plt.ylabel('Review Length (words)')
plt.title('Boxplot of Review Lengths by Sentiment')

plt.tight_layout()
plt.show()

# Visualize review length by domain
plt.figure(figsize=(14, 7))
sns.boxplot(data=review_analysis_df, x='Domain', y='Length', hue='Sentiment')
plt.xlabel('Domain')
plt.ylabel('Review Length (words)')
plt.title('Review Lengths by Domain and Sentiment')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Use the previously identified domains from sorted_data_acl directory
print(f"Available domains in the dataset: {domains}")

# Count reviews in each domain using XML parser
domain_counts = {}
for domain in domains:
    domain_dir = os.path.join(sorted_data_dir, domain)
    pos_path = os.path.join(domain_dir, "positive.review")
    neg_path = os.path.join(domain_dir, "negative.review")

    pos_reviews = extract_reviews_from_file(pos_path) if os.path.exists(pos_path) else []
    neg_reviews = extract_reviews_from_file(neg_path) if os.path.exists(neg_path) else []

    pos_count = len(pos_reviews)
    neg_count = len(neg_reviews)

    domain_counts[domain] = {'positive': pos_count, 'negative': neg_count, 'total': pos_count + neg_count}

# Convert to DataFrame and display
domain_df = pd.DataFrame.from_dict(domain_counts, orient='index')
print("\nReview counts by domain:")
print(domain_df)

# Visualize distribution of reviews across domains
plt.figure(figsize=(12, 6))
domain_df[['positive', 'negative']].plot(kind='bar', stacked=False)
plt.title('Distribution of Reviews Across Domains')
plt.xlabel('Domain')
plt.ylabel('Number of Reviews')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Define text cleaning functions

def clean_text(text):
    """
    Clean the text by:
    1. Converting to lowercase
    2. Removing HTML tags and entities
    3. Removing punctuation
    4. Removing numbers
    5. Removing extra whitespace
    """
    # Convert to lowercase
    text = text.lower()

    # Remove HTML tags and entities
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'&\w+;', '', text)

    # Remove punctuation
    text = re.sub(f'[{re.escape(string.punctuation)}]', ' ', text)

    # Remove numbers
    text = re.sub(r'\d+', '', text)

    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()

    return text

def remove_stopwords(text):
    """Remove common stopwords from text"""
    stop_words = set(stopwords.words('english'))
    word_tokens = word_tokenize(text)
    filtered_text = [word for word in word_tokens if word not in stop_words]
    return ' '.join(filtered_text)

def lemmatize_text(text):
    """Lemmatize text to reduce words to their root form"""
    lemmatizer = WordNetLemmatizer()
    word_tokens = word_tokenize(text)
    lemmatized_text = [lemmatizer.lemmatize(word) for word in word_tokens]
    return ' '.join(lemmatized_text)

def preprocess_text(text, remove_stops=True, lemmatize=True):
    """Apply full preprocessing pipeline to text"""
    text = clean_text(text)
    if remove_stops:
        text = remove_stopwords(text)
    if lemmatize:
        text = lemmatize_text(text)
    return text

# Test preprocessing on a sample review
if sample_pos_reviews:
    sample_review = sample_pos_reviews[0]
    print("Original review:")
    print(sample_review[:500] + "..." if len(sample_review) > 500 else sample_review)

    print("\nCleaned review:")
    cleaned_review = clean_text(sample_review)
    print(cleaned_review[:500] + "..." if len(cleaned_review) > 500 else cleaned_review)

    print("\nCleaned, stopwords removed, and lemmatized review:")
    fully_processed = preprocess_text(sample_review)
    print(fully_processed[:500] + "..." if len(fully_processed) > 500 else fully_processed)

# Function to load and preprocess reviews from all domains
def load_and_preprocess_domain_reviews(domain_list, sorted_data_dir):
    """
    Load and preprocess reviews from specified domains
    Returns:
        - texts: List of preprocessed review texts
        - labels: List of corresponding labels (1 for positive, 0 for negative)
        - domain_labels: List of domain identifiers for each review
    """
    all_texts = []
    all_labels = []
    all_domains = []

    print("Loading and preprocessing reviews from all domains...")

    for domain in domain_list:
        domain_dir = os.path.join(sorted_data_dir, domain)

        # Process positive reviews
        pos_path = os.path.join(domain_dir, "positive.review")
        if os.path.exists(pos_path):
            pos_reviews = extract_reviews_from_file(pos_path)
            print(f"Processing {len(pos_reviews)} positive reviews from {domain}...")

            # Process reviews in batches to show progress
            for i, review in enumerate(pos_reviews):
                if i % 100 == 0 and i > 0:
                    print(f"  Processed {i}/{len(pos_reviews)} positive reviews")

                preprocessed = preprocess_text(review)
                all_texts.append(preprocessed)
                all_labels.append(1)  # 1 for positive
                all_domains.append(domain)

        # Process negative reviews
        neg_path = os.path.join(domain_dir, "negative.review")
        if os.path.exists(neg_path):
            neg_reviews = extract_reviews_from_file(neg_path)
            print(f"Processing {len(neg_reviews)} negative reviews from {domain}...")

            for i, review in enumerate(neg_reviews):
                if i % 100 == 0 and i > 0:
                    print(f"  Processed {i}/{len(neg_reviews)} negative reviews")

                preprocessed = preprocess_text(review)
                all_texts.append(preprocessed)
                all_labels.append(0)  # 0 for negative
                all_domains.append(domain)

        # Process unlabeled reviews (just for counting/statistics, no labels)
        unlabeled_path = os.path.join(domain_dir, "unlabeled.review")
        if os.path.exists(unlabeled_path):
            unlabeled_reviews = extract_reviews_from_file(unlabeled_path)
            print(f"Found {len(unlabeled_reviews)} unlabeled reviews from {domain} (not used for training)")

    return all_texts, all_labels, all_domains

# Process all domains and create a dataset for sentiment analysis
print("\nProcessing all reviews from the available domains...")
processed_texts, labels, domain_labels = load_and_preprocess_domain_reviews(domains, sorted_data_dir)

# Create a DataFrame for easy manipulation
reviews_df = pd.DataFrame({
    'text': processed_texts,
    'sentiment': labels,
    'domain': domain_labels
})

print(f"\nTotal processed reviews: {len(reviews_df)}")
print(f"Positive reviews: {sum(reviews_df['sentiment'])}")
print(f"Negative reviews: {len(reviews_df) - sum(reviews_df['sentiment'])}")

# Display the first few rows of the DataFrame
print("\nSample of preprocessed reviews:")
print(reviews_df.head())

# Check for and remove very short reviews (potential outliers)
reviews_df['word_count'] = reviews_df['text'].apply(lambda x: len(x.split()))
min_words = 10  # Minimum word count threshold

print(f"\nRemoving reviews with fewer than {min_words} words...")
before_count = len(reviews_df)
reviews_df = reviews_df[reviews_df['word_count'] >= min_words]
after_count = len(reviews_df)
print(f"Removed {before_count - after_count} reviews.")

# Display distribution of reviews by domain
print("\nDistribution of reviews by domain after cleaning:")
domain_sentiment_counts = reviews_df.groupby(['domain', 'sentiment']).size().unstack()
print(domain_sentiment_counts)

# Plot distribution of reviews by domain and sentiment
plt.figure(figsize=(12, 6))
domain_sentiment_counts.plot(kind='bar', stacked=False)
plt.title('Distribution of Reviews by Domain and Sentiment After Cleaning')
plt.xlabel('Domain')
plt.ylabel('Number of Reviews')
plt.xticks(rotation=45)
plt.legend(['Negative', 'Positive'])
plt.tight_layout()
plt.show()

# Tokenize the text
print("Tokenizing and encoding text...")
max_words = 10000  # Maximum number of words to keep in the vocabulary
tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(reviews_df['text'])

# Convert text to sequences
sequences = tokenizer.texts_to_sequences(reviews_df['text'])

# Get basic statistics about sequence lengths
seq_lengths = [len(seq) for seq in sequences]
avg_seq_length = np.mean(seq_lengths)
median_seq_length = np.median(seq_lengths)
max_seq_length = np.max(seq_lengths)

print(f"Vocabulary size: {len(tokenizer.word_index)}")
print(f"Average sequence length: {avg_seq_length:.2f}")
print(f"Median sequence length: {median_seq_length:.2f}")
print(f"Maximum sequence length: {max_seq_length}")

# Visualize sequence lengths
plt.figure(figsize=(10, 6))
plt.hist(seq_lengths, bins=50)
plt.axvline(x=avg_seq_length, color='r', linestyle='--', label=f'Mean: {avg_seq_length:.2f}')
plt.axvline(x=median_seq_length, color='g', linestyle='--', label=f'Median: {median_seq_length:.2f}')
plt.xlabel('Sequence Length')
plt.ylabel('Frequency')
plt.title('Distribution of Sequence Lengths')
plt.legend()
plt.show()

# Determine appropriate max_length for padding (e.g., 95th percentile)
max_length = int(np.percentile(seq_lengths, 95))
print(f"Using max_length = {max_length} for padding (95th percentile)")

# Pad sequences
padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')

# Display a sample of padded sequences
print("\nSample padded sequence:")
print(padded_sequences[0])

# Check shape of the padded sequences
print(f"\nShape of padded sequences: {padded_sequences.shape}")

# Visualize a few padded sequences as heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(padded_sequences[:10], cmap='viridis')
plt.title('Visualization of Padded Sequences (First 10 Reviews)')
plt.xlabel('Token Position')
plt.ylabel('Review Index')
plt.show()

# Create labels array
labels_array = np.array(reviews_df['sentiment'])

# Split data into training, validation and test sets
# Use stratified split to maintain the same ratio of positive to negative reviews
X_train_val, X_test, y_train_val, y_test = train_test_split(
    padded_sequences,
    labels_array,
    test_size=0.15,
    random_state=42,
    stratify=labels_array
)

X_train, X_val, y_train, y_val = train_test_split(
    X_train_val,
    y_train_val,
    test_size=0.15,  # This gives ~15% validation, ~70% training, ~15% test
    random_state=42,
    stratify=y_train_val
)

print(f"Training set shape: {X_train.shape}, Labels: {y_train.shape}")
print(f"Validation set shape: {X_val.shape}, Labels: {y_val.shape}")
print(f"Test set shape: {X_test.shape}, Labels: {y_test.shape}")

# Check class balance in each set
print(f"\nTraining set - Positive: {sum(y_train)}, Negative: {len(y_train) - sum(y_train)}")
print(f"Validation set - Positive: {sum(y_val)}, Negative: {len(y_val) - sum(y_val)}")
print(f"Test set - Positive: {sum(y_test)}, Negative: {len(y_test) - sum(y_test)}")

# Visualize class distribution in each dataset
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))

# Training set
sns.countplot(x=y_train, ax=ax1)
ax1.set_title('Training Set Class Distribution')
ax1.set_xlabel('Sentiment (0=Negative, 1=Positive)')
ax1.set_ylabel('Count')

# Validation set
sns.countplot(x=y_val, ax=ax2)
ax2.set_title('Validation Set Class Distribution')
ax2.set_xlabel('Sentiment (0=Negative, 1=Positive)')
ax2.set_ylabel('Count')

# Test set
sns.countplot(x=y_test, ax=ax3)
ax3.set_title('Test Set Class Distribution')
ax3.set_xlabel('Sentiment (0=Negative, 1=Positive)')
ax3.set_ylabel('Count')

plt.tight_layout()
plt.show()

# Save preprocessed data (optional, for later use)
# np.save('X_train.npy', X_train)
# np.save('y_train.npy', y_train)
# np.save('X_val.npy', X_val)
# np.save('y_val.npy', y_val)

# Define model parameters
vocab_size = min(len(tokenizer.word_index) + 1, max_words) # +1 for OOV token
embedding_dim = 200

# Print model parameters
print(f"Vocabulary Size: {vocab_size}")
print(f"Embedding Dimension: {embedding_dim}")
print(f"Max Sequence Length: {max_length}")

# Define the model architecture
def create_model():
    model = Sequential([
        # Embedding layer
        Embedding(input_dim=vocab_size,
                  output_dim=embedding_dim,
                  input_length=max_length),

        # First Bidirectional LSTM layer with dropout
        Bidirectional(LSTM(64, return_sequences=True)),
        Dropout(0.3),

        # Second Bidirectional LSTM layer
        Bidirectional(LSTM(32)),
        Dropout(0.3),

        # Dense layers
        Dense(32, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid')  # Binary classification (positive/negative)
    ])

    return model

# Create and summarize the model
model = create_model()
model.summary()

# Visualize the model architecture (optional)
try:
    from tensorflow.keras.utils import plot_model
    plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)
    display(Image('model_architecture.png'))
except:
    print("Unable to display model architecture visualization. Continuing without it.")

# Compile the model
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Define callbacks for training
callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=3,
        restore_best_weights=True,
        verbose=1
    ),
    ModelCheckpoint(
        filepath='best_model.h5',
        monitor='val_loss',
        save_best_only=True,
        verbose=1
    )
]

# Define batch size and number of epochs
batch_size = 64
epochs = 10

# Train the model
print("Training the model...")
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=epochs,
    batch_size=batch_size,
    callbacks=callbacks,
    verbose=1
)

# Optionally save the model
model.save('sentiment_analysis_model.h5')
print("Model saved to 'sentiment_analysis_model.h5'")

# Plot training history
plt.figure(figsize=(12, 5))

# Plot training & validation accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')

# Plot training & validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')

plt.tight_layout()
plt.show()

# Get the best epoch (lowest validation loss)
best_epoch = np.argmin(history.history['val_loss']) + 1
best_val_loss = min(history.history['val_loss'])
best_val_acc = history.history['val_accuracy'][best_epoch-1]

print(f"Best epoch: {best_epoch}")
print(f"Best validation loss: {best_val_loss:.4f}")
print(f"Best validation accuracy: {best_val_acc:.4f}")

# Evaluate the model on the test set
print("Evaluating the model on the test set...")
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Make predictions on the test set
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int).flatten()

# Calculate and print classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Calculate and display confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
           xticklabels=['Negative', 'Positive'],
           yticklabels=['Negative', 'Positive'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()

# Look at some misclassified examples
misclassified_indices = np.where(y_pred != y_test)[0]

if len(misclassified_indices) > 0:
    print(f"\nNumber of misclassified examples: {len(misclassified_indices)}")

    # Get text of misclassified examples
    # First, get the original indices in the reviews_df
    test_indices = np.arange(len(padded_sequences))
    train_val_indices, test_indices_subset = train_test_split(
        test_indices, test_size=0.15, random_state=42, stratify=labels_array
    )

    # Get a few examples of misclassifications
    num_examples = min(5, len(misclassified_indices))
    for i in range(num_examples):
        idx = misclassified_indices[i]
        original_idx = test_indices_subset[idx]
        original_text = reviews_df.iloc[original_idx]['text']
        true_sentiment = 'Positive' if y_test[idx] == 1 else 'Negative'
        pred_sentiment = 'Positive' if y_pred[idx] == 1 else 'Negative'
        confidence = y_pred_prob[idx][0]

        print(f"\nMisclassified Example {i+1}:")
        print(f"Actual Sentiment: {true_sentiment}")
        print(f"Predicted Sentiment: {pred_sentiment}")
        print(f"Confidence: {confidence:.4f}")
        print(f"Text: {original_text[:200]}..." if len(original_text) > 200 else f"Text: {original_text}")
else:
    print("No misclassified examples found (perfect accuracy).")

# Calculate ROC curve and AUC
from sklearn.metrics import roc_curve, auc

fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

# Define a function to preprocess and predict sentiment for new text
def predict_sentiment(text, model, tokenizer, max_length):
    """
    Process new text and predict its sentiment using the trained model

    Args:
        text: String containing the review text
        model: Trained Keras model
        tokenizer: Fitted tokenizer
        max_length: Max sequence length for padding

    Returns:
        sentiment: String ('Positive' or 'Negative')
        confidence: Float representing model confidence (0-1)
    """
    # Clean and preprocess the text
    processed_text = preprocess_text(text)

    # Convert to sequence and pad
    sequence = tokenizer.texts_to_sequences([processed_text])
    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')

    # Predict
    prediction = model.predict(padded)[0][0]

    # Determine sentiment and confidence
    sentiment = "Positive" if prediction >= 0.5 else "Negative"
    confidence = prediction if sentiment == "Positive" else 1 - prediction

    return sentiment, confidence

# Create a more user-friendly prediction function with detailed output
def analyze_review_sentiment(review_text, model, tokenizer, max_length):
    """
    Analyze the sentiment of a product review with detailed output

    Args:
        review_text: String containing the review text
        model: Trained Keras model
        tokenizer: Fitted tokenizer
        max_length: Max sequence length for padding

    Returns:
        None (prints analysis results)
    """
    # Get raw prediction
    sentiment, confidence = predict_sentiment(review_text, model, tokenizer, max_length)

    # Format confidence as percentage
    confidence_percent = confidence * 100

    # Define confidence levels
    if confidence >= 0.8:
        confidence_level = "Very high confidence"
    elif confidence >= 0.6:
        confidence_level = "High confidence"
    elif confidence >= 0.4:
        confidence_level = "Moderate confidence"
    else:
        confidence_level = "Low confidence"

    # Print analysis
    print("=" * 80)
    print("SENTIMENT ANALYSIS RESULTS")
    print("=" * 80)
    print(f"Review text: {review_text[:150]}..." if len(review_text) > 150 else f"Review text: {review_text}")
    print("-" * 80)
    print(f"Predicted Sentiment: {sentiment}")
    print(f"Confidence: {confidence_percent:.2f}% ({confidence_level})")
    print("=" * 80)

    return sentiment, confidence

# Define some test reviews that weren't part of the training data
test_reviews = [
    "This product exceeded my expectations. The quality is outstanding and customer service was excellent!",
    "I love this product! It's exactly what I was looking for and works perfectly.",
    "Terrible experience. The product broke after a week and customer service was unhelpful.",
    "Not worth the money. Cheaply made and doesn't work as advertised.",
    "Mixed feelings about this purchase. Some features work well, but others are disappointing.",
    "The product is okay, not great, not terrible. It does the job but there's definitely room for improvement.",
    "I have been using this for three months and it has become an essential part of my daily routine.",
    "The delivery was quick but the product doesn't match the description on the website."
]

# Analyze each test review
print("Testing our model on new, unseen reviews:")

results = []
for i, review in enumerate(test_reviews):
    print(f"\nTest Review #{i+1}:")
    sentiment, confidence = analyze_review_sentiment(review, model, tokenizer, max_length)
    results.append({
        'review': review,
        'predicted_sentiment': sentiment,
        'confidence': confidence
    })

# Convert results to DataFrame for analysis
results_df = pd.DataFrame(results)

# Visualize confidence distribution
plt.figure(figsize=(10, 6))
sns.barplot(x=results_df.index, y='confidence', hue='predicted_sentiment', data=results_df)
plt.title('Model Confidence for Test Reviews')
plt.xlabel('Review Index')
plt.ylabel('Confidence Score')
plt.ylim(0, 1)
plt.xticks(results_df.index)
plt.tight_layout()
plt.show()

print("\nTesting on samples from the unlabeled reviews in each domain:")

# Function to get sample unlabeled reviews from a domain
def get_sample_unlabeled_reviews(domain, num_samples=2):
    unlabeled_path = os.path.join(sorted_data_dir, domain, "unlabeled.review")
    if not os.path.exists(unlabeled_path):
        return []

    # Read all reviews
    all_reviews = extract_reviews_from_file(unlabeled_path)

    # Select random samples
    import random
    random.seed(42 + hash(domain))  # Different seed for each domain
    if len(all_reviews) <= num_samples:
        return all_reviews
    return random.sample(all_reviews, num_samples)

# Get and analyze unlabeled samples from each domain
for domain in domains:
    samples = get_sample_unlabeled_reviews(domain)
    if samples:
        print(f"\nUnlabeled reviews from {domain} domain:")
        for i, review in enumerate(samples):
            print(f"\n{domain.capitalize()} Review #{i+1}:")
            analyze_review_sentiment(review, model, tokenizer, max_length)
    else:
        print(f"\nNo unlabeled reviews found for {domain} domain")

# Create an interactive demo (for Google Colab)
from IPython.display import HTML, display

def create_interactive_demo():
    """Creates an interactive demo for sentiment analysis in Colab"""
    html = """
    <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px; margin: 10px 0;">
        <h3 style="text-align: center; color: #343a40;">Sentiment Analysis Interactive Demo</h3>
        <p style="text-align: center;">Enter a product review to analyze its sentiment:</p>
        <textarea id="review_text" style="width: 100%; height: 100px; padding: 10px; margin-bottom: 10px; border-radius: 5px; border: 1px solid #ced4da;"></textarea>
        <button id="analyze_button" style="background-color: #007bff; color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; display: block; margin: 0 auto;">Analyze Sentiment</button>
        <div id="result" style="margin-top: 20px; padding: 15px; border-radius: 5px; display: none;"></div>
    </div>

    <script>
    function analyzeReview() {
        var reviewText = document.getElementById('review_text').value;
        if (reviewText.trim() === '') {
            alert('Please enter a review to analyze.');
            return;
        }

        document.getElementById('analyze_button').disabled = true;
        document.getElementById('analyze_button').innerHTML = 'Analyzing...';

        google.colab.kernel.invokeFunction('notebook.analyze_sentiment', [reviewText], {});
    }

    document.getElementById('analyze_button').addEventListener('click', analyzeReview);
    </script>
    """
    display(HTML(html))

    def display_result(sentiment, confidence):
        confidence_percent = confidence * 100
        color = "#28a745" if sentiment == "Positive" else "#dc3545"

        result_html = f"""
        <div id="result" style="margin-top: 20px; padding: 15px; border-radius: 5px; background-color: {color}; color: white;">
            <h4 style="margin-top: 0;">Sentiment: {sentiment}</h4>
            <p style="margin-bottom: 0;">Confidence: {confidence_percent:.2f}%</p>
        </div>

        <script>
        document.getElementById('analyze_button').disabled = false;
        document.getElementById('analyze_button').innerHTML = 'Analyze Sentiment';
        </script>
        """
        display(HTML(result_html))

    # Register the callback function
    from google.colab import output
    output.register_callback('notebook.analyze_sentiment',
                            lambda text: display_result(*predict_sentiment(text, model, tokenizer, max_length)))

try:
    # Check if running in Colab
    import google.colab
    print("Creating interactive demo...")
    create_interactive_demo()
    print("Enter a review in the text area and click 'Analyze Sentiment'")
except:
    print("Interactive demo is only available in Google Colab environment.")

# Save the model, excluding the optimizer
model.save('sentiment_analysis_model.h5', save_format='h5', include_optimizer=False)
print("Model saved to 'sentiment_analysis_model.h5' (optimizer excluded)")

import os

# Search for any .h5 files in the current directory and subdirectories
for root, dirs, files in os.walk('.'):
    for file in files:
        if file.endswith('.h5'):
            print(f"Found model: {os.path.join(root, file)}")

model.save('best_model.h5')

import streamlit as st
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load the model
model = tf.keras.models.load_model('sentiment_analysis_model.h5')
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Re-compile

# Initialize tokenizer in session state
if 'tokenizer' not in st.session_state:
    st.session_state.tokenizer = Tokenizer()

tokenizer = st.session_state.tokenizer
# Streamlit App Interface
st.title('Sentiment Analysis Interactive Demo')
st.markdown("Enter your text below to analyze its sentiment:")

# Text input from user
user_input = st.text_area("Input Text", "Type your text here...")

if st.button('Analyze Sentiment'):
    if user_input:
        try:
            # Tokenize and pad the input text
            sequences = tokenizer.texts_to_sequences([user_input])
            padded_sequences = pad_sequences(sequences, maxlen=100)  # Adjust 'maxlen' as needed

            # Predict the sentiment
            prediction = model.predict(padded_sequences)

            # Handle the prediction result and ensure it's correctly formatted
            if prediction is not None:
                sentiment = "Positive" if prediction[0][0] > 0.5 else "Negative"
                confidence = prediction[0][0] if sentiment == "Positive" else 1 - prediction[0][0]

                # Display result dynamically
                st.markdown(f"### Sentiment: {sentiment}")
                st.markdown(f"### Confidence: {confidence * 100:.2f}%")

                # Style the result based on sentiment
                color = "#28a745" if sentiment == "Positive" else "#dc3545"
                st.markdown(f'<div style="background-color: {color}; color: white; padding: 10px; border-radius: 5px;">'
                            f'<h4>{sentiment} Sentiment</h4>'
                            f'<p>Confidence: {confidence * 100:.2f}%</p>'
                            f'</div>', unsafe_allow_html=True)
            else:
                st.write("The model returned no prediction.")
        except Exception as e:
            st.write(f"Error during prediction: {e}")
    else:
        st.write("Please enter some text to analyze.")

